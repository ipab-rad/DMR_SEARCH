{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMR Practical Assignment: Recover a broken robot\n",
    "\n",
    "## Recursive Bayesian estimation\n",
    "\n",
    "Localisation is a key problem in robotics, and a number of approaches have been proposed to address this. Recursive Bayesian estimation using the discrete Bayes filter is one such approach. \n",
    "\n",
    "We start by assuming that a robot has state $\\mathbf{x}_k$ at time step $k$, and can be commanded to take actions $\\mathbf{a}_k$. Let us also assume that the robot is able to sense the environment it finds itself in and obtains measurement $\\mathbf{z}_k$.\n",
    "\n",
    "Recursive Bayesian estimation is a sequential technique for maintaining a belief over a state, conditioned on a series of measurements, $p(\\mathbf{x}_k|\\mathbf{z}_{1:k})$. We briefly derive the equations for recursive Bayesian estimation below. First, we will use Bayes rule to rewrite the desired posterior belief,\n",
    "\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k}) = \\frac{p(\\mathbf{z}_{1:k}|\\mathbf{x}_k)p(\\mathbf{x}_k)}{p(\\mathbf{z}_{1:k})}$$\n",
    "\n",
    "We factorise the trajectory likelihood $p(\\mathbf{z}_{1:k}|\\mathbf{x}_k)$ in the numerator, to produce\n",
    "\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k}) = \\frac{p(\\mathbf{z}_{k}|\\mathbf{x}_k,\\mathbf{z}_{1:k-1})p(\\mathbf{z}_{1:k-1}|\\mathbf{x}_k)p(\\mathbf{x}_k)}{p(\\mathbf{z}_{k}|\\mathbf{z}_{1:k-1})p(\\mathbf{z}_{1:k-1})}$$\n",
    "\n",
    "The second half of this equation can be simplified using Bayes rule, providing:\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k}) = \\frac{p(\\mathbf{z}_{k}|\\mathbf{x}_k,\\mathbf{z}_{1:k-1})p(\\mathbf{x}_k|\\mathbf{z}_{1:k-1})}{p(\\mathbf{z}_{k}|\\mathbf{z}_{1:k-1})}$$\n",
    "\n",
    "Let us assume that our robot is Markovian, that is, measurements $\\mathbf{z}_k$ are only dependent on state $\\mathbf{x}_k$, and state $\\mathbf{x}_k$ is only dependent on previous state $\\mathbf{x}_{k-1}$. Then we can simplify the equation above even further,\n",
    "\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k}) = \\frac{p(\\mathbf{z}_{k}|\\mathbf{x}_k)p(\\mathbf{x}_k|\\mathbf{z}_{1:k-1})}{p(\\mathbf{z}_{k}|\\mathbf{z}_{1:k-1})}$$\n",
    "\n",
    "This equation is pretty interesting, the first part $p(\\mathbf{z}_{k}|\\mathbf{x}_k)$ is a likelihood - how likely are you to make the measurement $\\mathbf{z}_k$ given you are in state $\\mathbf{x}_k$. The denominator bit is just a normalising term, so we'll ignore this.\n",
    "\n",
    "The term $p(\\mathbf{x}_k|\\mathbf{z}_{1:k-1})$ is a prediction of the state given the history of measurements. Lets assume we have a transition model of robot motion $p(\\mathbf{x}_k|\\mathbf{x}_{k-1},\\mathbf{a}_k)$. Then we can make a prediction about where our robot will be for a given state if we apply an action.\n",
    "\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k-1}) = \\int{p(\\mathbf{x}_k|\\mathbf{x}_{k-1},\\mathbf{a}_k)p(\\mathbf{x}_{k-1}|\\mathbf{z}_{1:k-1})\\text{d}\\mathbf{x}_{k-1}}$$\n",
    "\n",
    "This equation is extremely powerful - it computes the probability of occupying a state for a given action, by taking into account all the possible states we could have come from, along with the prior belief that we had in these states, $p(\\mathbf{x}_{k-1}|\\mathbf{z}_{1:k-1})$. This is called the total probability rule.\n",
    "\n",
    "What's key here is that we have a recursive means of maintaining a belief over the world as we take actions, given a model of how we gain information from the world, and a model of how we interact with the world. This allows us to continue to update our beliefs as we act in the world and receive new information.\n",
    "\n",
    "To summarise, first we make a prediction about the likely state of the world if we were to take an action:\n",
    "\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k-1}) = \\int{p(\\mathbf{x}_k|\\mathbf{x}_{k-1},\\mathbf{a}_k)p(\\mathbf{x}_{k-1}|\\mathbf{z}_{1:k-1})\\text{d}\\mathbf{x}_{k-1}}$$\n",
    "\n",
    "Then we take the action, sense the world and update our belief in the states.\n",
    "\n",
    "$$p(\\mathbf{x}_k|\\mathbf{z}_{1:k}) \\propto p(\\mathbf{z}_{k}|\\mathbf{x}_k)p(\\mathbf{x}_k|\\mathbf{z}_{1:k-1})$$\n",
    "\n",
    "We repeat this as new information is gathered and actions are taken, continually refining our beliefs.\n",
    "\n",
    "\n",
    "## The discrete Bayes filter (DBF)\n",
    "\n",
    "The discrete Bayes filter is a discrete form of recursive Bayesian estimation. Here, we discretise the world into a number of possible states $\\mathbf{x}^j$, and maintain beliefs using discrete random variables for each possible state.\n",
    "\n",
    "Since our belief is over a finite set of $j$ states, the integral in the equation above changes to a sum for the discrete bayes filter prediction step,\n",
    "\n",
    "$$p(\\mathbf{x}^j_k|\\mathbf{z}_{1:k-1}) = \\sum_{x_i}{p(\\mathbf{x}^j_k|\\mathbf{x}^i_{k-1},\\mathbf{a}_k)p(\\mathbf{x}^i_{k-1}|\\mathbf{z}_{1:k-1})}$$\n",
    "\n",
    "Then we sense the world and update our belief in the states.\n",
    "\n",
    "$$p(\\mathbf{x}^j_k|\\mathbf{z}_{1:k}) \\propto p(\\mathbf{z}_{k}|\\mathbf{x}^j_k)p(\\mathbf{x}^j_k|\\mathbf{z}_{1:k-1})$$\n",
    "\n",
    "References:\n",
    "http://www.probabilistic-robotics.org/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from helper_funcs import Robot, make_world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Let us assume you have a faulty robot equipped with a metal detector. The robot can sense if there is metal near it (p_sense_succeed = 0.8), but occasionally it's sensors fail (p_sense_fail = 0.2) and it returns the wrong measurement.\n",
    "\n",
    "The robot can take random actions to move a step to the left, right, up, down, or diagonally, but this is also unreliable. Sometimes it behaves (p_move_succeed = 0.9), but occasionally it just stays where it was (p_move_fail = 0.1)\n",
    "\n",
    "Unfortunately, your robot is lost somewhere in a grid. Luckily, it managed to make a map of locations of the metal in the world before getting lost. Your goal is to use this map, together with sensor measurements, to figure out where your robot is so that you can recover it.\n",
    "\n",
    "Complete the program below to implement the prediction and likelihood calculations for a discrete Bayes filter, in order to find out where your robot is. One you have completed this, compile a report including images of the distributions at convergence, and briefly discussing your solutions.\n",
    "\n",
    "Try to answer at least three of the following questions in the report:\n",
    "\n",
    "* How quickly does the DBF converge to a good belief? (re-run multiple times)\n",
    "* How do the sensing and move failure probabilities affect inference?\n",
    "* How does the environment affect the quality of the belief in position?\n",
    "* How does the predictive distribution change the posterior from one time step before?\n",
    "* When is an MMSE estimator a good one? Are there better estimators for this problem?\n",
    "* When would the best time to attempt to recover your robot be?\n",
    "* Assume you can choose actions to take instead of executing random ones. What actions could you take to reduce the uncertainty in the robot position?\n",
    "\n",
    "This task is inspired by the search for the wreckage of Air France Flight AF 4471\n",
    "https://arxiv.org/pdf/1405.4720.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise world and agent in it\n",
    "p_move = 0.9\n",
    "p_sense = 0.8\n",
    "\n",
    "world = make_world()\n",
    "N = world.shape[0]\n",
    "\n",
    "agent = Robot(p_move,p_sense,world)\n",
    "\n",
    "# Create list of possible states in world (x,y coordinates)\n",
    "possible_states = np.array(np.meshgrid(np.linspace(0,N-1,N),np.linspace(0,N-1,N))).reshape(2,-1).T\n",
    "\n",
    "# Initialise belief in position - uniform distribution over world\n",
    "state_belief = np.ones((N,N))/(N*N)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(world)\n",
    "plt.title('Map of the world (1-yellow/metal, 0-blue/no metal)')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the discrete Bayes filter\n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "for j in range(200):\n",
    "    \n",
    "    # Sample a random action\n",
    "    a = np.sign((np.random.rand(2,)-0.5))\n",
    "    \n",
    "    # Apply action and sense\n",
    "    measurement = agent.move_and_sense(a)\n",
    "    \n",
    "    # Make prediction about state belief given action\n",
    "    predicted_state_belief = np.zeros((N,N))\n",
    "    for state in possible_states.astype(int):\n",
    "        \n",
    "        new_state = agent.move_perfect(state,a)\n",
    "        \n",
    "############################ Complete this section ##########################################\n",
    "        \n",
    "        ## predicted_state_belief[new_state[0],new_state[1]] = \n",
    "\n",
    "#############################################################################################\n",
    "   \n",
    "    # Evaluate sensor belief for each possible state\n",
    "    likelihood = np.zeros((N,N))\n",
    "    for state in possible_states.astype(int):\n",
    "        \n",
    "############################ Complete this section ##########################################\n",
    "        \n",
    "        #Hint the expected measurement in a given state is world[state[0],state[1]]\n",
    "    \n",
    "        ## likelihood[state[0],state[1]] = \n",
    "            \n",
    "#############################################################################################\n",
    "    \n",
    "    # Compute posterior belief over possible states\n",
    "    state_belief = likelihood*predicted_state_belief\n",
    "    \n",
    "    # Tip: never become overconfident, so add some probability mass to all possible states before normalising\n",
    "    state_belief = (state_belief+1e-15)\n",
    "    state_belief = state_belief/np.sum(state_belief) \n",
    "    \n",
    "    # Compute posterior mean, minimimum mean squared error estimator\n",
    "    mmse_estimate = np.sum(possible_states*state_belief.T.reshape(-1,1),axis=0)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.subplot(2,4,1)\n",
    "    plt.cla()\n",
    "    plt.imshow(agent.visualise_true_position())\n",
    "    plt.title('True position in world')\n",
    "    \n",
    "    plt.subplot(2,4,2)\n",
    "    plt.cla()\n",
    "    plt.imshow(predicted_state_belief)\n",
    "    plt.title('Predicted belief given action')\n",
    "    \n",
    "    plt.subplot(2,4,3)\n",
    "    plt.cla()\n",
    "    plt.imshow(likelihood)\n",
    "    plt.title('Likelihood')\n",
    "    \n",
    "    plt.subplot(2,4,4)\n",
    "    plt.cla()\n",
    "    plt.imshow(state_belief)\n",
    "    plt.title('Posterior belief given measurement')\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(agent.get_mse(mmse_estimate))\n",
    "    plt.grid()\n",
    "    plt.title('MMSE position error')\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
